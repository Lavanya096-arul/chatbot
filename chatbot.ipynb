{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdWlT4KXyEzy"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain_google_genai langgraph fastapi uvicorn nest-asyncio pyngrok streamlit requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass(\"enter google api key\")\n",
        "\n",
        "\n",
        "ngrok_authtoken = getpass(\"Enter your ngrok authtoken: \")\n",
        "if ngrok_authtoken:\n",
        "    ngrok.set_auth_token(ngrok_authtoken)\n",
        "    print(\"ngrok authtoken set.\")\n",
        "else:\n",
        "    print(\"No ngrok authtoken provided ‚Äî you must provide it to expose services publicly from Colab.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E552Wy37yboj",
        "outputId": "721d87a6-6ab9-4eef-95b1-9738082e5afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter google api key¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter your ngrok authtoken: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "ngrok authtoken set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backend_code = r'''\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-lite\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "class ChatState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder_chat = StateGraph(ChatState)\n",
        "\n",
        "def chatbot(state: ChatState) -> ChatState:\n",
        "    return {\"messages\": gemini_llm.invoke(state[\"messages\"])}\n",
        "\n",
        "graph_builder_chat.add_node(\"chatbot\", chatbot)\n",
        "graph_builder_chat.add_edge(START, \"chatbot\")\n",
        "graph_builder_chat.add_edge(\"chatbot\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph_memory = graph_builder_chat.compile(checkpointer=memory)\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class UserMessage(BaseModel):\n",
        "    message: str\n",
        "\n",
        "HISTORY_FILE = \"chat_history.json\"\n",
        "\n",
        "def extract_text(msg):\n",
        "    if isinstance(msg, dict):\n",
        "        return msg.get(\"content\") or msg.get(\"text\") or msg.get(\"message\") or str(msg)\n",
        "    if hasattr(msg, \"content\"):\n",
        "        return getattr(msg, \"content\")\n",
        "    return str(msg)\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def chat(user_message: UserMessage):\n",
        "    response = graph_memory.invoke(\n",
        "        ChatState(messages=[{\"role\": \"user\", \"content\": user_message.message}]),\n",
        "        config\n",
        "    )\n",
        "    last = response[\"messages\"][-1]\n",
        "    reply = extract_text(last)\n",
        "    try:\n",
        "        with open(HISTORY_FILE, \"r\") as f:\n",
        "            history = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        history = []\n",
        "    history.append({\n",
        "        \"user\": user_message.message,\n",
        "        \"bot\": reply,\n",
        "        \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\"\n",
        "    })\n",
        "    with open(HISTORY_FILE, \"w\") as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "    return {\"reply\": reply}\n",
        "'''\n",
        "\n",
        "with open(\"backend.py\", \"w\") as f:\n",
        "    f.write(backend_code)\n",
        "\n",
        "print(\"backend.py written to disk.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB2HpPijyg7F",
        "outputId": "6e17efdb-9af8-424a-d165-7371c8b9ff85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "backend.py written to disk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "get_ipython().system_raw(\"uvicorn backend:app --host 0.0.0.0 --port 8000 &\")\n",
        "\n",
        "try:\n",
        "    public_tunnel = ngrok.connect(8000)\n",
        "    backend_public_url = public_tunnel.public_url\n",
        "    print(\"‚úÖ FastAPI public URL:\", backend_public_url)\n",
        "    print(\"üëâ Open this link in a new browser tab to check the backend.\")\n",
        "except Exception as e:\n",
        "    backend_public_url = \"http://127.0.0.1:8000\"\n",
        "    print(\"‚ö†Ô∏è Couldn't open ngrok tunnel (maybe authtoken missing). Using local URL:\", backend_public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgVeBO9qyouu",
        "outputId": "be6017a7-31cb-4a6e-c97e-04fda37fa797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ FastAPI public URL: https://unreferred-jo-uredinial.ngrok-free.dev\n",
            "üëâ Open this link in a new browser tab to check the backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backend_url = globals().get(\"backend_public_url\", \"http://127.0.0.1:8000\")\n",
        "streamlit_code = f'''\n",
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "BACKEND_URL = \"{backend_url}\"\n",
        "\n",
        "st.set_page_config(page_title=\"Gemini Chatbot\", page_icon=\"ü§ñ\")\n",
        "st.title(\"ü§ñ Gemini Chatbot (LangGraph + FastAPI)\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "def send_message(text):\n",
        "    resp = requests.post(f\"{{BACKEND_URL}}/chat\", json={{\"message\": text}}, timeout=120)\n",
        "    return resp.json().get(\"reply\")\n",
        "\n",
        "with st.form(\"chat_form\", clear_on_submit=True):\n",
        "    user_input = st.text_input(\"You:\")\n",
        "    submitted = st.form_submit_button(\"Send\")\n",
        "    if submitted and user_input:\n",
        "        reply = send_message(user_input)\n",
        "        st.session_state.messages.append({{\"sender\":\"You\", \"text\": user_input}})\n",
        "        st.session_state.messages.append({{\"sender\":\"Bot\", \"text\": reply}})\n",
        "\n",
        "for msg in st.session_state.messages:\n",
        "    if msg[\"sender\"] == \"You\":\n",
        "        st.markdown(f\"**You:** {{msg['text']}}\")\n",
        "    else:\n",
        "        st.markdown(f\"**Bot:** {{msg['text']}}\")\n",
        "\n",
        "if st.button(\"Save chat to file (downloadable)\"):\n",
        "    with open(\"chat_history_saved.json\", \"w\") as f:\n",
        "        json.dump(st.session_state.messages, f, indent=2)\n",
        "    st.success(\"Saved to chat_history_saved.json (see files on the left).\")\n",
        "'''\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "print(\"app.py written (Streamlit frontend). Backend URL used:\", backend_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2IOOg0kyvF6",
        "outputId": "d2830a19-4e9b-4f52-9f40-cc041d35f709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py written (Streamlit frontend). Backend URL used: https://unreferred-jo-uredinial.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Start Streamlit server in background\n",
        "get_ipython().system_raw(\"streamlit run app.py --server.port 8501 &\")\n",
        "\n",
        "try:\n",
        "    streamlit_url = ngrok.connect(8501).public_url\n",
        "    print(\"Streamlit public URL:\", streamlit_url)\n",
        "except Exception as e:\n",
        "    streamlit_url = \"http://127.0.0.1:8501\"\n",
        "    print(\"Couldn't open ngrok tunnel for Streamlit (maybe authtoken missing). Streamlit local URL:\", streamlit_url)\n",
        "\n",
        "# Display clickable link in Colab output\n",
        "display(Markdown(f\"[Open Streamlit app]({streamlit_url})\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "XVzItDKUyz5j",
        "outputId": "0c5c17f6-8f34-412d-b8cd-fcb5e57a1e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: https://unreferred-jo-uredinial.ngrok-free.dev\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "[Open Streamlit app](https://unreferred-jo-uredinial.ngrok-free.dev)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_GgjpK4h47_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}